import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time
import datetime
from pyvirtualdisplay import Display
import random

# Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
MAIN_URL = "https://coursatk.online/years"
OUTPUT_FILE = "index.html"

# --- ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ù†ØµØ© (Ø§Ù„Ø®Ø²Ù†Ø©) ---
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Academy - Ø§Ù„Ø®Ø²Ù†Ø©</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        :root {{ --primary: #fbbf24; --bg: #1a1a1a; --card: #2d2d2d; --text: #eaeaea; }}
        body {{ font-family: Tahoma, sans-serif; background: var(--bg); color: var(--text); padding: 20px; }}
        header {{ text-align: center; border-bottom: 2px solid var(--primary); padding-bottom: 20px; margin-bottom: 30px; }}
        
        .grid {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 20px; }}
        .card {{ background: var(--card); border-radius: 12px; overflow: hidden; border: 1px solid #444; display: flex; flex-direction: column; }}
        
        .video-box {{ position: relative; padding-bottom: 56.25%; height: 0; background: #000; border-bottom: 1px solid #444; }}
        .video-box iframe, .video-box video {{ position: absolute; top: 0; left: 0; width: 100%; height: 100%; }}
        
        .card-body {{ padding: 15px; flex-grow: 1; }}
        .card-title {{ font-size: 1.1rem; color: var(--primary); font-weight: bold; margin-bottom: 10px; }}
        .path {{ font-size: 0.8rem; color: #888; margin-bottom: 10px; }}
        
        .btn {{ display: block; background: #2563eb; color: white; text-align: center; padding: 10px; border-radius: 6px; text-decoration: none; font-weight: bold; margin-top: auto; }}
        .btn:hover {{ background: #1d4ed8; }}
        
        .stats {{ background: #333; padding: 15px; border-radius: 8px; margin-bottom: 20px; text-align: center; color: #aaa; font-family: monospace; }}
    </style>
</head>
<body>
    <header>
        <h1>ğŸ’ ACADEMY VAULT</h1>
        <p>ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù† Ø§Ù„Ø¹Ù…Ù‚</p>
    </header>

    <div class="stats">
        {stats}
    </div>

    <div class="grid">
        {content}
    </div>
</body>
</html>
"""

def deep_excavator():
    # 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø´Ø§Ø´Ø© Ø§Ù„ÙˆÙ‡Ù…ÙŠØ© ÙˆØ§Ù„Ù…ØªØµÙØ­
    print("ğŸšœ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­ÙØ§Ø±...")
    display = Display(visible=0, size=(1920, 1080))
    display.start()

    options = uc.ChromeOptions()
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-popup-blocking')
    
    driver = uc.Chrome(options=options)
    
    extracted_data = [] # Ù‡Ù†Ø§ Ù‡Ù†Ø®Ø²Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ù„ÙŠ Ù†Ù„Ø§Ù‚ÙŠÙ‡Ø§
    visited_urls = set() # Ø¹Ø´Ø§Ù† Ù…Ù†Ø¯Ø®Ù„Ø´ ØµÙØ­Ø© Ù…Ø±ØªÙŠÙ†
    urls_to_visit = [MAIN_URL] # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù„ÙŠ Ù‡ÙŠÙ…Ø´ÙŠ Ø¹Ù„ÙŠÙ‡Ø§ (Ø·Ø§Ø¨ÙˆØ±)

    try:
        # 2. Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠ ÙˆØ§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ÙŠØ¯ÙˆÙŠ
        print(f"ğŸŒ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ù…ÙˆÙ‚Ø¹: {MAIN_URL}")
        driver.get(MAIN_URL)
        
        print("â³ Ù…Ø¹Ùƒ 60 Ø«Ø§Ù†ÙŠØ© Ø§Ù„Ø¢Ù†! Ù„Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø­ØªØ§Ø¬ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ØŒ Ø§Ø¯Ø®Ù„ Ø¨Ø­Ø³Ø§Ø¨Ùƒ ÙŠØ¯ÙˆÙŠØ§Ù‹...")
        # Ù‡Ù†Ø§ Ø¨Ù†Ø¯ÙŠÙƒ ÙˆÙ‚Øª Ù„Ùˆ Ø¹Ø§ÙŠØ² ØªØ¹Ù…Ù„ login
        time.sleep(60) 
        
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø²Ø­Ù Ø§Ù„Ø¹Ù…ÙŠÙ‚! (Ù‡ÙŠØ§Ø®Ø¯ ÙˆÙ‚ØªØŒ Ø³ÙŠØ¨Ù‡ ÙŠØ´ØªØºÙ„)...")

        # 3. Ø­Ù„Ù‚Ø© Ø§Ù„Ø²Ø­Ù (Crawler Loop)
        # Ù‡Ù†Ù„Ù Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ 50 ØµÙØ­Ø© Ø¹Ø´Ø§Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…ÙŠÙØµÙ„Ø´ (Ù…Ù…ÙƒÙ† ØªØ²ÙˆØ¯Ù‡Ø§)
        max_pages = 50 
        pages_scanned = 0

        while urls_to_visit and pages_scanned < max_pages:
            current_url = urls_to_visit.pop(0) # Ø®Ø¯ Ø£ÙˆÙ„ Ø±Ø§Ø¨Ø· ÙÙŠ Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
            
            if current_url in visited_urls:
                continue
            
            try:
                print(f"[{pages_scanned+1}/{max_pages}] Ø¬Ø§Ø±ÙŠ ÙØ­Øµ: {current_url}")
                driver.get(current_url)
                time.sleep(5) # Ø§Ø³ØªÙ†Ù‰ Ø§Ù„ØµÙØ­Ø© ØªØ­Ù…Ù„
                visited_urls.add(current_url)
                pages_scanned += 1

                soup = BeautifulSoup(driver.page_source, 'html.parser')
                page_title = soup.title.text.strip() if soup.title else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"

                # --- Ø£. Ø§Ù„ØªÙØªÙŠØ´ Ø¹Ù† ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø¯ÙŠ ---
                found_on_page = False
                
                # 1. Iframes
                for iframe in soup.find_all('iframe'):
                    src = iframe.get('src')
                    if src and ("youtube" in src or "vimeo" in src or "video" in src or "embed" in src):
                        extracted_data.append({
                            "type": "iframe", "src": src, "title": page_title, "origin": current_url
                        })
                        found_on_page = True
                        print("   âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆ!")

                # 2. Video Tags
                for vid in soup.find_all('video'):
                    src = vid.get('src')
                    if src:
                        full_src = urljoin(current_url, src)
                        extracted_data.append({
                            "type": "video", "src": full_src, "title": page_title, "origin": current_url
                        })
                        found_on_page = True
                        print("   âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù ÙÙŠØ¯ÙŠÙˆ!")

                # --- Ø¨. Ù„Ùˆ Ù…ÙÙŠØ´ ÙÙŠØ¯ÙŠÙˆØŒ Ø¯ÙˆØ± Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· ØªØ§Ù†ÙŠØ© ÙˆØ¶ÙŠÙÙ‡Ø§ Ù„Ù„Ø·Ø§Ø¨ÙˆØ± ---
                # (Ø¨Ø³ Ù†Ø¶ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© ÙÙ‚Ø· Ø¹Ø´Ø§Ù† Ù…ÙŠØ³Ø±Ø­Ø´ ÙÙŠ Ø¬ÙˆØ¬Ù„ ÙˆÙÙŠØ³Ø¨ÙˆÙƒ)
                if not found_on_page:
                    links = soup.find_all('a', href=True)
                    for link in links:
                        href = link['href']
                        full_link = urljoin(current_url, href)
                        
                        # Ø´Ø±ÙˆØ· Ø§Ù„Ø±Ø§Ø¨Ø· Ø¹Ø´Ø§Ù† Ù†Ø¯Ø®Ù„Ù‡:
                        # 1. ÙŠÙƒÙˆÙ† ØªØ¨Ø¹ Ø§Ù„Ù…ÙˆÙ‚Ø¹ (Ù…Ø´ Ø®Ø§Ø±Ø¬ÙŠ)
                        # 2. Ù…ÙŠÙƒÙˆÙ†Ø´ Ø²Ø±Ø§Ø± Ø®Ø±ÙˆØ¬ Ø£Ùˆ Ù„ÙˆØ¬ÙŠÙ†
                        # 3. Ù…ÙŠÙƒÙˆÙ†Ø´ Ø´ÙˆÙÙ†Ø§Ù‡ Ù‚Ø¨Ù„ ÙƒØ¯Ø©
                        if "coursatk.online" in full_link and full_link not in visited_urls and full_link not in urls_to_visit:
                            if not any(x in full_link for x in ["login", "logout", "register", "#", "contact"]):
                                urls_to_visit.append(full_link)

            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØµÙØ­Ø©: {e}")

        # 4. Ø¨Ù†Ø§Ø¡ Ù…Ù„Ù HTML Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        html_cards = ""
        if not extracted_data:
            html_cards = "<h2 style='text-align:center; padding:50px; color:#ef4444'>Ù„Ù„Ø£Ø³Ù Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ø­ØªÙ‰ Ø¨Ø¹Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚.</h2>"
        else:
            for item in extracted_data:
                media_html = ""
                btn_text = ""
                btn_link = item['src']

                if item['type'] == 'iframe':
                    media_html = f'<iframe src="{item["src"]}" allowfullscreen></iframe>'
                    btn_text = "Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ù…ØµØ¯Ø±"
                else:
                    media_html = f'<video controls src="{item["src"]}"></video>'
                    btn_text = "ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"

                html_cards += f"""
                <div class="card">
                    <div class="video-box">{media_html}</div>
                    <div class="card-body">
                        <div class="card-title">{item['title']}</div>
                        <div class="path">Ø§Ù„Ù…ØµØ¯Ø±: {item['origin']}</div>
                        <a href="{btn_link}" class="btn" target="_blank">{btn_text}</a>
                    </div>
                </div>
                """

        stats_text = f"ØªÙ… Ù…Ø³Ø­ {pages_scanned} ØµÙØ­Ø© | ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(extracted_data)} ÙÙŠØ¯ÙŠÙˆ"
        
        final_html = HTML_TEMPLATE.format(stats=stats_text, content=html_cards)
        
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            f.write(final_html)
        
        print(f"ğŸ‰ ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡! Ø§Ù„Ù†ØªÙŠØ¬Ø©: {stats_text}")

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ù‚Ø§ØªÙ„: {e}")
    finally:
        driver.quit()
        display.stop()

if __name__ == "__main__":
    deep_excavator()
